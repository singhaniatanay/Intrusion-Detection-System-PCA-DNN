{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET LOADING / SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/home/singhaniatanay18/X_resampled.csv')\n",
    "Y = pd.read_csv('./Y_resampled.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7477003, 35)\n",
      "(7477003, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "catenc = pd.factorize(Y.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7477003, 1)\n"
     ]
    }
   ],
   "source": [
    "Y2 = pd.DataFrame(data=catenc[0])\n",
    "print(Y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5009592, 35)\n",
      "(5009592, 1)\n",
      "(2467411, 35)\n",
      "(2467411, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y2, test_size=0.33, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5009592, 1)\n",
      "(5009592, 35)\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "Xtr_np = np.array(X_train)\n",
    "Ytr_np = np.array(y_train)\n",
    "print(Ytr_np.shape)\n",
    "print(Xtr_np.shape)\n",
    "print(type(Ytr_np[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(torch.Tensor(Xtr_np), torch.Tensor(Ytr_np))\n",
    "torch.save(train,'train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xte_np = np.array(X_test)\n",
    "Yte_np = np.array(y_test)\n",
    "test = torch.utils.data.TensorDataset(torch.Tensor(Xte_np), torch.Tensor(Yte_np))\n",
    "torch.save(test,'test.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = torch.load('train.pt')\n",
    "te = torch.load('test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(tr, batch_size = 1024, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(te, batch_size = 1024, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4893\n",
      "2410\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([8.0000e+01, 5.0110e+06, 4.0000e+00, 6.5696e+02, 6.5696e+02, 0.0000e+00,\n",
      "        1.6424e+02, 3.2848e+02, 1.9761e+03, 5.2546e+02, 1.5965e+00, 7.1585e+05,\n",
      "        1.8912e+06, 5.0048e+06, 2.1727e+01, 2.0653e+03, 1.5030e+03, 3.6911e+02,\n",
      "        5.0109e+06, 1.6703e+06, 2.8881e+06, 5.0052e+06, 9.2000e+01, 9.2000e+01,\n",
      "        7.9825e-01, 0.0000e+00, 2.9256e+02, 4.4680e+05, 1.0000e+00, 0.0000e+00,\n",
      "        1.0000e+00, 8.1920e+03, 2.2098e+02, 2.0000e+01, 0.0000e+00]), tensor([14.]))\n"
     ]
    }
   ],
   "source": [
    "print(tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "\n",
    "scaler.fit(tr.tensors[0])\n",
    "# Apply transform to both the training set and the test set.\n",
    "train_scaled = scaler.transform(tr.tensors[0])\n",
    "test__scaled = scaler.transform(te.tensors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5009592, 35)\n"
     ]
    }
   ],
   "source": [
    "print(train_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an instance of the Model\n",
    "pca = PCA(.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=0.95, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "train_PCA = pca.transform(train_scaled)\n",
    "test_PCA = pca.transform(test__scaled)\n",
    "print(type(train_PCA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = torch.utils.data.TensorDataset(torch.Tensor(train_PCA), torch.Tensor(tr.tensors[1]))\n",
    "torch.save(train2,'train_PCA.pt')\n",
    "test2 = torch.utils.data.TensorDataset(torch.Tensor(test_PCA), torch.Tensor(te.tensors[1]))\n",
    "torch.save(test2,'test_PCA.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr2 = torch.load('train_PCA.pt')\n",
    "te2 = torch.load('test_PCA.pt')\n",
    "train_loader = torch.utils.data.DataLoader(tr2, batch_size = 2048, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(te2, batch_size = 1024, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2447\n",
      "2410\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(16, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 32)\n",
    "        self.fc4 = nn.Linear(32, 32)\n",
    "        self.fc5 = nn.Linear(32, 32)\n",
    "        self.fc6 = nn.Linear(32, 30)\n",
    "        self.fc7 = nn.Linear(30, 28)\n",
    "        self.fc8 = nn.Linear(28, 28)\n",
    "        self.fc9 = nn.Linear(28, 28)\n",
    "        self.fc10 = nn.Linear(28, 15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = F.relu(self.fc9(x))\n",
    "        x = self.fc10(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n",
      "running on GPU\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda:0')\n",
    "print(device)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('running on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=16, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (fc5): Linear(in_features=32, out_features=32, bias=True)\n",
      "  (fc6): Linear(in_features=32, out_features=30, bias=True)\n",
      "  (fc7): Linear(in_features=30, out_features=28, bias=True)\n",
      "  (fc8): Linear(in_features=28, out_features=28, bias=True)\n",
      "  (fc9): Linear(in_features=28, out_features=28, bias=True)\n",
      "  (fc10): Linear(in_features=28, out_features=15, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_function = nn.NLLLoss()\n",
    "loss_function = nn.MultiLabelMarginLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.06899018585681915: 0it [01:36, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 ; Curr itr : 2447/2447 ; Loss : 0.06899018585681915 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.11847180873155594: 0it [01:36, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 2 ; Curr itr : 2447/2447 ; Loss : 0.11847180873155594 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.022922059521079063: 0it [01:35, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 3 ; Curr itr : 2447/2447 ; Loss : 0.022922059521079063 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.049855269491672516: 0it [01:35, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 ; Curr itr : 2447/2447 ; Loss : 0.049855269491672516 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.04039812833070755: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 5 ; Curr itr : 2447/2447 ; Loss : 0.04039812833070755 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.06646371632814407: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 6 ; Curr itr : 2447/2447 ; Loss : 0.06646371632814407 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.03838426619768143: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 7 ; Curr itr : 2447/2447 ; Loss : 0.03838426619768143 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.06797514855861664: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 8 ; Curr itr : 2447/2447 ; Loss : 0.06797514855861664 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]46/2447 ; Loss : 0.026663407683372498: 0it [01:35, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 9 ; Curr itr : 2447/2447 ; Loss : 0.026663407683372498 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.027178604155778885: 0it [01:35, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10 ; Curr itr : 2447/2447 ; Loss : 0.027178604155778885 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.04381397366523743: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 11 ; Curr itr : 2447/2447 ; Loss : 0.04381397366523743 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.08811794221401215: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 12 ; Curr itr : 2447/2447 ; Loss : 0.08811794221401215 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.04020896926522255: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 13 ; Curr itr : 2447/2447 ; Loss : 0.04020896926522255 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.009729876182973385: 0it [01:35, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 14 ; Curr itr : 2447/2447 ; Loss : 0.009729876182973385 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.01651344634592533: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 15 ; Curr itr : 2447/2447 ; Loss : 0.01651344634592533 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.0375649519264698: 0it [01:36, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 16 ; Curr itr : 2447/2447 ; Loss : 0.0375649519264698 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.07670526206493378: 0it [01:36, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 17 ; Curr itr : 2447/2447 ; Loss : 0.07670526206493378 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.05506826937198639: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 18 ; Curr itr : 2447/2447 ; Loss : 0.05506826937198639 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.0370330773293972: 0it [01:34, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 19 ; Curr itr : 2447/2447 ; Loss : 0.0370330773293972 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.05818483233451843: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 20 ; Curr itr : 2447/2447 ; Loss : 0.05818483233451843 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.04608724266290665: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 21 ; Curr itr : 2447/2447 ; Loss : 0.04608724266290665 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.0514913946390152: 0it [01:35, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 22 ; Curr itr : 2447/2447 ; Loss : 0.0514913946390152 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.011800400912761688: 0it [01:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 23 ; Curr itr : 2447/2447 ; Loss : 0.011800400912761688 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.02652999386191368: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 24 ; Curr itr : 2447/2447 ; Loss : 0.02652999386191368 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.0342918261885643: 0it [01:35, ?it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 25 ; Curr itr : 2447/2447 ; Loss : 0.0342918261885643 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.01263155322521925: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 26 ; Curr itr : 2447/2447 ; Loss : 0.01263155322521925 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.047541793435811996: 0it [01:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 27 ; Curr itr : 2447/2447 ; Loss : 0.047541793435811996 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.047023508697748184: 0it [01:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 28 ; Curr itr : 2447/2447 ; Loss : 0.047023508697748184 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.01118483766913414: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 29 ; Curr itr : 2447/2447 ; Loss : 0.01118483766913414 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.013394554145634174: 0it [01:34, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 30 ; Curr itr : 2447/2447 ; Loss : 0.013394554145634174 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.08414938300848007: 0it [01:35, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 31 ; Curr itr : 2447/2447 ; Loss : 0.08414938300848007 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0it [00:00, ?it/s]446/2447 ; Loss : 0.04923718050122261: 0it [01:34, ?it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 32 ; Curr itr : 2447/2447 ; Loss : 0.04923718050122261 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch : 33 ; Curr itr : 338/2447 ; Loss : 0.03797025606036186: 0it [00:13, ?it/s] "
     ]
    }
   ],
   "source": [
    "total = len(train_loader)\n",
    "loss_list = []\n",
    "for epoch in range(100):\n",
    "    i =0# 3 full passes over the data\n",
    "    outer = tqdm(total=0, desc='Epoch', position=0)\n",
    "    for data in train_loader:\n",
    "        xx,yy = data# X is the batch of features, y is the batch of targets.\n",
    "        #print(xx.size(1))\n",
    "        xx = xx.to(device)\n",
    "        yy = yy.to(device)\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(xx.view(xx.size(0), -1))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        #print('output nikla')\n",
    "        #print(output.size(1))\n",
    "        #print(yy.size(1))\n",
    "        yy = yy.squeeze(1)\n",
    "        loss = F.nll_loss(output, yy.long())  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "        loss_list.append(float(loss))\n",
    "        outer.set_description_str(f'Epoch : {epoch} ; Curr itr : {i}/{total} ; Loss : {loss}')\n",
    "        i +=1\n",
    "    print(f'Epoch : {epoch} ; Curr itr : {i}/{total} ; Loss : {loss} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(net,'MultiLabelMarginLoss3_PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Itr :2409/2410:   0%|          | 0/2410 [04:12<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.984\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "itr = 0\n",
    "with torch.no_grad():\n",
    "    ooo = tqdm(total=len(test_loader), desc='Itr', position=0)\n",
    "    for data in test_loader:\n",
    "        xx, y = data\n",
    "        xx = xx.to(device)\n",
    "        y = y.to(device)\n",
    "        output = net(xx.view(xx.size(0), -1))\n",
    "        y = y.squeeze(1)\n",
    "        y = y.long()\n",
    "        #print(output)\n",
    "        \n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "        ooo.set_description_str(f'Itr :{itr}/{len(test_loader)}')\n",
    "        itr+=1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
